{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "03_minibatch_training.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvegWVaBQ6Ms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "749b3314-db05-4dcc-9d3b-6ae1455edbca"
      },
      "source": [
        "!curl -s https://course.fast.ai/setup/colab | bash\n",
        "!pip install fire\n",
        "%matplotlib inline\n",
        "from fastai.basics import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n",
            "Collecting fire\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire) (1.1.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=8ce510c15ee607ee99d7510d4159d49e9673e7c42f39c851a3f293cc5ebf96e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgrGbFZoQ7_G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "ba515d6c-6f52-4922-fa9e-d957a1d20f2e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "%cd '/content/gdrive/My Drive/Colab Notebooks/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaB6qW5YQuHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdEQ2bjTQuHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from exp.nb_02 import *\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPBvTb_LQuHh",
        "colab_type": "text"
      },
      "source": [
        "## Initial setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6QGWan1QuHi",
        "colab_type": "text"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq_1Snl6QuHj",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=1786)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1awTAweQuHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mpl.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxANRaKsQuHr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9c383ad-299b-4ab7-f4d8-330384507785"
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = get_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://deeplearning.net/data/mnist/mnist.pkl.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_cMcMCzSFbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_data??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ9Or-z1QuHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "nh = 50"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39iDKytFQuH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsRJaoJrQuH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSO8Il44QuID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model(x_train)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTBGUuoxQuIN",
        "colab_type": "text"
      },
      "source": [
        "### Cross entropy loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6SS7rs1QuIO",
        "colab_type": "text"
      },
      "source": [
        "First, we will need to compute the softmax of our activations. This is defined by:\n",
        "\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$$\n",
        "\n",
        "or more concisely:\n",
        "\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{\\sum_{0 \\leq j \\leq n-1} e^{x_{j}}}$$ \n",
        "\n",
        "In practice, we will need the log of the softmax when we calculate the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jacnLD7LQuIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE1XLjuNQuIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sm_pred = log_softmax(pred)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID-Dw9b2TXRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "c9af1b5b-afc7-49b0-b4f3-fe3c8c9de966"
      },
      "source": [
        "sm_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.4501, -2.4524, -2.5212,  ..., -2.1887, -2.3749, -2.0884],\n",
              "        [-2.3381, -2.4527, -2.5815,  ..., -2.3327, -2.2770, -2.1172],\n",
              "        [-2.3375, -2.4866, -2.5488,  ..., -2.2588, -2.2789, -2.1084],\n",
              "        ...,\n",
              "        [-2.3276, -2.4568, -2.5773,  ..., -2.3165, -2.2281, -2.1334],\n",
              "        [-2.4225, -2.4035, -2.4772,  ..., -2.2841, -2.2598, -2.2259],\n",
              "        [-2.3302, -2.4266, -2.5312,  ..., -2.3524, -2.1693, -2.2019]],\n",
              "       grad_fn=<LogBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a29MyBKtTP09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "1518a1bf-a326-46b6-eb7d-0f7df444c81e"
      },
      "source": [
        "sm_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0863, 0.0861, 0.0804,  ..., 0.1121, 0.0930, 0.1239],\n",
              "        [0.0965, 0.0861, 0.0757,  ..., 0.0970, 0.1026, 0.1204],\n",
              "        [0.0966, 0.0832, 0.0782,  ..., 0.1045, 0.1024, 0.1214],\n",
              "        ...,\n",
              "        [0.0975, 0.0857, 0.0760,  ..., 0.0986, 0.1077, 0.1184],\n",
              "        [0.0887, 0.0904, 0.0840,  ..., 0.1019, 0.1044, 0.1080],\n",
              "        [0.0973, 0.0883, 0.0796,  ..., 0.0951, 0.1143, 0.1106]],\n",
              "       grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UtmwPbyQuIa",
        "colab_type": "text"
      },
      "source": [
        "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n",
        "\n",
        "$$ -\\sum x\\, \\log p(x) $$\n",
        "\n",
        "But since our $x$s are 1-hot encoded, this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdFKXuXAQuIb",
        "colab_type": "text"
      },
      "source": [
        "This can be done using numpy-style [integer array indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html#integer-array-indexing). Note that PyTorch supports all the tricks in the advanced indexing methods discussed in that link."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6Qt0Q4_QuId",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63164587-7ad2-41a3-fb47-aae55dce9f73"
      },
      "source": [
        "y_train[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ24F6HHQuIj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "583985b3-6fe0-4e00-bd39-9723033cb03f"
      },
      "source": [
        "sm_pred[[0,1,2], [5,0,4]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.4321, -2.3381, -2.2050], grad_fn=<IndexBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zL6qAJBYwYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a16b9ff1-5ca6-4d81-9547-b6f5339385b5"
      },
      "source": [
        "sm_pred.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50000, 10]), torch.Size([50000]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSDjoRA6QuIp",
        "colab_type": "code",
        "colab": {},
        "outputId": "52cbbaee-baeb-4eb0-b9c2-93bea7bb080f"
      },
      "source": [
        "y_train.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POXFtORIQuIv",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=2081)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db3yYcZMQuIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nll(input, target): return -input[range(target.shape[0]), target].mean()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTun31isXU2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = [1,1,1,1]\n",
        "input = [[0,1],[0,4], [1,5],[0,0]]\n",
        "#target = np.array(target, dtype=np.float32)\n",
        "input = np.array(input, dtype=np.float32)\n",
        "input, target = map(tensor,(input, target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czjztk-aaeNs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96af6ffb-fc43-485d-bb13-b66b607301ec"
      },
      "source": [
        "input[range(target.shape[0]),target]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aa8KTqmYG2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5685aea6-84ce-4415-c221-8ceaec80d4c6"
      },
      "source": [
        "loss = nll(input,target)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-2.5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOMxrXeDQuI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = nll(sm_pred, y_train)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCwEslMqQuI5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13c058ea-cec8-4570-cd05-b8ac1884e32c"
      },
      "source": [
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3110, grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1XZm9uDQuI_",
        "colab_type": "text"
      },
      "source": [
        "Note that the formula \n",
        "\n",
        "$$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$ \n",
        "\n",
        "gives a simplification when we compute the log softmax, which was previously defined as `(x.exp()/(x.exp().sum(-1,keepdim=True))).log()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFlcVqZ5QuJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x - x.exp().sum(-1,keepdim=True).log()\n",
        "#def log_softmax(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibynQxlQQuJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebpjMP9LQuJJ",
        "colab_type": "text"
      },
      "source": [
        "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the [LogSumExp trick](https://en.wikipedia.org/wiki/LogSumExp). The idea is to use the following formula:\n",
        "\n",
        "$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n",
        "\n",
        "where a is the maximum of the $x_{j}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig60scjXQuJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logsumexp(x):\n",
        "    m = x.max(-1)[0]\n",
        "    return m + (x-m[:,None]).exp().sum(-1).log()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZpzYQbvQuJO",
        "colab_type": "text"
      },
      "source": [
        "This way, we will avoid an overflow when taking the exponential of a big activation. In PyTorch, this is already implemented for us. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNEhlEWPQuJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(logsumexp(pred), pred.logsumexp(-1))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsG6ZQJ7QuJT",
        "colab_type": "text"
      },
      "source": [
        "So we can use it for our `log_softmax` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThuhBHeQQuJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x - x.logsumexp(-1,keepdim=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOznlTH_QuJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHBguhpiQuJg",
        "colab_type": "text"
      },
      "source": [
        "Then use PyTorch's implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEumjYAYQuJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(F.nll_loss(F.log_softmax(pred, -1), y_train), loss)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8zi6SzdQuJr",
        "colab_type": "text"
      },
      "source": [
        "In PyTorch, `F.log_softmax` and `F.nll_loss` are combined in one optimized function, `F.cross_entropy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_sIsZ5gQuJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(F.cross_entropy(pred, y_train), loss)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-Zn_no2QuJz",
        "colab_type": "text"
      },
      "source": [
        "## Basic training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "443IG62yQuJ1",
        "colab_type": "text"
      },
      "source": [
        "Basically the training loop repeats over the following steps:\n",
        "- get the output of the model on a batch of inputs\n",
        "- compare the output to the labels we have and compute a loss\n",
        "- calculate the gradients of the loss with respect to every parameter of the model\n",
        "- update said parameters with those gradients to make them a little bit better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNry2Zn9QuJ1",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=2542)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOUjqQBOQuJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = F.cross_entropy"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JZhI3UDQuJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIR8RpTzQuKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6b345e32-6c92-4d9f-e255-ad7c9dd02d49"
      },
      "source": [
        "bs=64                  # batch size\n",
        "\n",
        "xb = x_train[0:bs]     # a mini-batch from x\n",
        "preds = model(xb)      # predictions\n",
        "preds[0], preds.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.0944,  0.1856,  0.1121,  0.0239, -0.0287, -0.0344,  0.1583,  0.1404,\n",
              "         -0.1669, -0.3139], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1MYHPPAQuKF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea74bc55-4d9b-4e58-923f-94d4caf431c7"
      },
      "source": [
        "yb = y_train[0:bs]\n",
        "loss_func(preds, yb)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3140, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBb3KW2_QuKK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8fe20d26-56d6-4c0e-c179-04a3e3e86a05"
      },
      "source": [
        "accuracy(preds, yb)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1094)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoSDmzT_QuKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.5   # learning rate\n",
        "epochs = 1 # how many epochs to train for"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dS_Gxz7QuKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "#         set_trace()\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        loss = loss_func(model(xb), yb)\n",
        "\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            for l in model.layers:\n",
        "                if hasattr(l, 'weight'):\n",
        "                    l.weight -= l.weight.grad * lr\n",
        "                    l.bias   -= l.bias.grad   * lr\n",
        "                    l.weight.grad.zero_()\n",
        "                    l.bias  .grad.zero_()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkymXNSdQuKW",
        "colab_type": "code",
        "colab": {},
        "outputId": "2b070476-fa2a-4ea4-c6dd-2c3883ed3d9c"
      },
      "source": [
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3465, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF37wxJ3QuKb",
        "colab_type": "text"
      },
      "source": [
        "## Using parameters and optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7SkhJE4QuKc",
        "colab_type": "text"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYGZpLqpQuKe",
        "colab_type": "text"
      },
      "source": [
        "Use `nn.Module.__setattr__` and move relu to functional:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSFqtnIRQuKf",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=2818)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VjAYWf6QuKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(n_in,nh)\n",
        "        self.l2 = nn.Linear(nh,n_out)\n",
        "        \n",
        "    def __call__(self, x): return self.l2(F.relu(self.l1(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc0GwN2BQuKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WjJ6qCBQuKq",
        "colab_type": "code",
        "colab": {},
        "outputId": "be38ec20-68d7-4752-c604-cfb394e89a51"
      },
      "source": [
        "for name,l in model.named_children(): print(f\"{name}: {l}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "l1: Linear(in_features=784, out_features=50, bias=True)\n",
            "l2: Linear(in_features=50, out_features=10, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq7Oby4yQuKu",
        "colab_type": "code",
        "colab": {},
        "outputId": "caa203e5-f4a7-4c2a-a22d-c6ddd6f2f4e2"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ba8380YQuKz",
        "colab_type": "code",
        "colab": {},
        "outputId": "232b09f1-8ff5-474d-ffe3-3f2efe79bea3"
      },
      "source": [
        "model.l1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=50, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIsg8rCVQuK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for i in range((n-1)//bs + 1):\n",
        "            start_i = i*bs\n",
        "            end_i = start_i+bs\n",
        "            xb = x_train[start_i:end_i]\n",
        "            yb = y_train[start_i:end_i]\n",
        "            loss = loss_func(model(xb), yb)\n",
        "\n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters(): p -= p.grad * lr\n",
        "                model.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdmiVbfsQuLF",
        "colab_type": "code",
        "colab": {},
        "outputId": "9df1c23a-992a-428c-f6ca-9eb8c7526979"
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1094, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNDz43dVQuLK",
        "colab_type": "text"
      },
      "source": [
        "Behind the scenes, PyTorch overrides the `__setattr__` function in `nn.Module` so that the submodules you define are properly registered as parameters of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7cYiJM7QuLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DummyModule():\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        self._modules = {}\n",
        "        self.l1 = nn.Linear(n_in,nh)\n",
        "        self.l2 = nn.Linear(nh,n_out)\n",
        "        \n",
        "    def __setattr__(self,k,v):\n",
        "        if not k.startswith(\"_\"): self._modules[k] = v\n",
        "        super().__setattr__(k,v)\n",
        "        \n",
        "    def __repr__(self): return f'{self._modules}'\n",
        "    \n",
        "    def parameters(self):\n",
        "        for l in self._modules.values():\n",
        "            for p in l.parameters(): yield p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jItznJVQuLO",
        "colab_type": "code",
        "colab": {},
        "outputId": "b176ee1f-41b9-43b3-d37e-92a31e404a36"
      },
      "source": [
        "mdl = DummyModule(m,nh,10)\n",
        "mdl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSRP2eDmQuLV",
        "colab_type": "code",
        "colab": {},
        "outputId": "9f01a678-4bc1-4672-9647-4a1f4d08cc0a"
      },
      "source": [
        "[o.shape for o in mdl.parameters()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([50, 784]),\n",
              " torch.Size([50]),\n",
              " torch.Size([10, 50]),\n",
              " torch.Size([10])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAKYOy-PQuLZ",
        "colab_type": "text"
      },
      "source": [
        "### Registering modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiczrGB8QuLa",
        "colab_type": "text"
      },
      "source": [
        "We can use the original `layers` approach, but we have to register the modules."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8LY-U9OQuLb",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=2997)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyopI8uzQuLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u49rP6RzQuLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktRIb0wxQuLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sSS70FGQuLt",
        "colab_type": "code",
        "colab": {},
        "outputId": "afd155c3-a356-46be-91d8-7a88f23525d5"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (layer_1): ReLU()\n",
              "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6FdDPRTQuL0",
        "colab_type": "text"
      },
      "source": [
        "### nn.ModuleList"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keZoA8h-QuL1",
        "colab_type": "text"
      },
      "source": [
        "`nn.ModuleList` does this for us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-3BsGqTQuL2",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3173)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp_1_WkVQuL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequentialModel(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXPn5mkfQuL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SequentialModel(layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-qyCKNyQuMH",
        "colab_type": "code",
        "colab": {},
        "outputId": "fc6595a7-6003-4df0-9aaf-5d0c22938621"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kFY216PQuML",
        "colab_type": "code",
        "colab": {},
        "outputId": "5b4a26d2-07bb-49fb-d5d2-2087aee5e962"
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2131, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC3BhZ9WQuMO",
        "colab_type": "text"
      },
      "source": [
        "### nn.Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzXSnOh1QuMP",
        "colab_type": "text"
      },
      "source": [
        "`nn.Sequential` is a convenient class which does the same as the above:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecw7dxcUQuMQ",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3199)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN9AKOUNQuMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR2343djQuMb",
        "colab_type": "code",
        "colab": {},
        "outputId": "a60d2e5c-3225-45d9-d605-3ec9e7a25e6f"
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2167, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKFHsnOCQuMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.Sequential??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFXs9vo8QuMp",
        "colab_type": "code",
        "colab": {},
        "outputId": "405e949d-8c44-4eca-d1aa-6dc1d9712b54"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyJ3x5FdQuMy",
        "colab_type": "text"
      },
      "source": [
        "### optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DZic6C8QuMz",
        "colab_type": "text"
      },
      "source": [
        "Let's replace our previous manually coded optimization step:\n",
        "\n",
        "```python\n",
        "with torch.no_grad():\n",
        "    for p in model.parameters(): p -= p.grad * lr\n",
        "    model.zero_grad()\n",
        "```\n",
        "\n",
        "and instead use just:\n",
        "\n",
        "```python\n",
        "opt.step()\n",
        "opt.zero_grad()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhUMwEfiQuM0",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3278)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0ytqYZTQuM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optimizer():\n",
        "    def __init__(self, params, lr=0.5): self.params,self.lr=list(params),lr\n",
        "        \n",
        "    def step(self):\n",
        "        with torch.no_grad():\n",
        "            for p in self.params: p -= p.grad * lr\n",
        "\n",
        "    def zero_grad(self):\n",
        "        for p in self.params: p.grad.data.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jorzsE7QuM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwTMljvYQuNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Optimizer(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMozIowXQuNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCl4ROpvQuNJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "e639d7b8-bc8e-4dd2-9980-1a4cc0b51003"
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "loss,acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0797, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ify2zH_zQuNM",
        "colab_type": "text"
      },
      "source": [
        "PyTorch already provides this exact functionality in `optim.SGD` (it also handles stuff like momentum, which we'll look at later - except we'll be doing it in a more flexible way!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjoW1iR0QuNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch import optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rKSmYFBQuNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim.SGD.step??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwmHNV0yQuNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
        "    return model, optim.SGD(model.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4on0WAJ6QuNY",
        "colab_type": "code",
        "colab": {},
        "outputId": "d78664d3-4810-4d69-96ec-3556890666f6"
      },
      "source": [
        "model,opt = get_model()\n",
        "loss_func(model(xb), yb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3222, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttN3pMDAQuNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exoNmbM0QuNk",
        "colab_type": "code",
        "colab": {},
        "outputId": "30f5d85b-09a4-43c6-bc70-7d775c77d22f"
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "loss,acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0436, grad_fn=<NllLossBackward>), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnM7U55ZQuNp",
        "colab_type": "text"
      },
      "source": [
        "Randomized tests can be very useful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmuAuRUlQuNq",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3442)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt7RteN7QuNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert acc>0.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Rwt_1vFQuNv",
        "colab_type": "text"
      },
      "source": [
        "## Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haPxP0tGQuNw",
        "colab_type": "text"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btYT__4qQuNw",
        "colab_type": "text"
      },
      "source": [
        "It's clunky to iterate through minibatches of x and y values separately:\n",
        "\n",
        "```python\n",
        "    xb = x_train[start_i:end_i]\n",
        "    yb = y_train[start_i:end_i]\n",
        "```\n",
        "\n",
        "Instead, let's do these two steps together, by introducing a `Dataset` class:\n",
        "\n",
        "```python\n",
        "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC21vqCzQuNx",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3578)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebmSGdqOQuNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "class Dataset():\n",
        "    def __init__(self, x, y): self.x,self.y = x,y\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self, i): return self.x[i],self.y[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Alu4QW2QuN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
        "assert len(train_ds)==len(x_train)\n",
        "assert len(valid_ds)==len(x_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "askf80cAQuN5",
        "colab_type": "code",
        "colab": {},
        "outputId": "43e2c377-094b-4180-de76-f8b80da67cc0"
      },
      "source": [
        "xb,yb = train_ds[0:5]\n",
        "assert xb.shape==(5,28*28)\n",
        "assert yb.shape==(5,)\n",
        "xb,yb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([5, 0, 4, 1, 9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPLsnACJQuN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model,opt = get_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7ONSl1fQuOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1tvR61CQuOI",
        "colab_type": "code",
        "colab": {},
        "outputId": "8a708666-29e0-4990-d2d3-a30814ba1f7c"
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4507, grad_fn=<NllLossBackward>), tensor(0.8750))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwOI_vgsQuOP",
        "colab_type": "text"
      },
      "source": [
        "### DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31W7Bu9aQuOP",
        "colab_type": "text"
      },
      "source": [
        "Previously, our loop iterated over batches (xb, yb) like this:\n",
        "\n",
        "```python\n",
        "for i in range((n-1)//bs + 1):\n",
        "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "    ...\n",
        "```\n",
        "\n",
        "Let's make our loop much cleaner, using a data loader:\n",
        "\n",
        "```python\n",
        "for xb,yb in train_dl:\n",
        "    ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAydFTyWQuOQ",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3674)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ5E1h6HQuOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "    def __init__(self, ds, bs): self.ds,self.bs = ds,bs\n",
        "    def __iter__(self):\n",
        "        for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_zrCSYbQuOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs)\n",
        "valid_dl = DataLoader(valid_ds, bs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlMwSIHUQuOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb,yb = next(iter(valid_dl))\n",
        "assert xb.shape==(bs,28*28)\n",
        "assert yb.shape==(bs,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfCEe2vLQuOk",
        "colab_type": "code",
        "colab": {},
        "outputId": "7e82e1e9-4655-4a71-d25f-d232a0d349ad"
      },
      "source": [
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPw6XVUlQuOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model,opt = get_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0RaX7jWQuOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for xb,yb in train_dl:\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vapRL0qdQuOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IklXIpt5QuOz",
        "colab_type": "code",
        "colab": {},
        "outputId": "803620e6-59f4-4f81-ef18-c84cf0b8f5a0"
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0762, grad_fn=<NllLossBackward>), tensor(0.9844))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt92tPlmQuO2",
        "colab_type": "text"
      },
      "source": [
        "### Random sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I77uljR7QuO3",
        "colab_type": "text"
      },
      "source": [
        "We want our training set to be in a random order, and that order should differ each iteration. But the validation set shouldn't be randomized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q77Nx9klQuO3",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3942)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzw7EmpkQuO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sampler():\n",
        "    def __init__(self, ds, bs, shuffle=False):\n",
        "        self.n,self.bs,self.shuffle = len(ds),bs,shuffle\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
        "        for i in range(0, self.n, self.bs): yield self.idxs[i:i+self.bs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBiprnZKQuO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "small_ds = Dataset(*train_ds[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqsaf_pfQuO-",
        "colab_type": "code",
        "colab": {},
        "outputId": "106830f2-28dc-4a8a-8f6d-a556e1fefeb1"
      },
      "source": [
        "s = Sampler(small_ds,3,False)\n",
        "[o for o in s]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlf9l55LQuPE",
        "colab_type": "code",
        "colab": {},
        "outputId": "809cfdf9-686c-4b83-85e4-91f6824d4293"
      },
      "source": [
        "s = Sampler(small_ds,3,True)\n",
        "[o for o in s]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([8, 0, 3]), tensor([5, 1, 2]), tensor([7, 6, 4]), tensor([9])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vbhUI-mQuPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate(b):\n",
        "    xs,ys = zip(*b)\n",
        "    return torch.stack(xs),torch.stack(ys)\n",
        "\n",
        "class DataLoader():\n",
        "    def __init__(self, ds, sampler, collate_fn=collate):\n",
        "        self.ds,self.sampler,self.collate_fn = ds,sampler,collate_fn\n",
        "        \n",
        "    def __iter__(self):\n",
        "        for s in self.sampler: yield self.collate_fn([self.ds[i] for i in s])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3RtgVcKQuPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_samp = Sampler(train_ds, bs, shuffle=True)\n",
        "valid_samp = Sampler(valid_ds, bs, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkWWCfM4QuPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, sampler=train_samp, collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, sampler=valid_samp, collate_fn=collate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID-BHJ8pQuPR",
        "colab_type": "code",
        "colab": {},
        "outputId": "3a2f7041-e6e8-490a-aa8e-0517d8fed11a"
      },
      "source": [
        "xb,yb = next(iter(valid_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhc2wj8MQuPX",
        "colab_type": "code",
        "colab": {},
        "outputId": "d900c0d8-a299-457c-98f8-1daedc02f0d4"
      },
      "source": [
        "xb,yb = next(iter(train_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htAjPA2ZQuPa",
        "colab_type": "code",
        "colab": {},
        "outputId": "8cc74f20-4cd2-4138-926e-478bf35371e8"
      },
      "source": [
        "xb,yb = next(iter(train_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWZTrRCzQuPi",
        "colab_type": "code",
        "colab": {},
        "outputId": "614332df-b689-4bca-ca9a-62967baa013d"
      },
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "\n",
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2939, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44t3JvkPQuPm",
        "colab_type": "text"
      },
      "source": [
        "### PyTorch DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhpHItM9QuPn",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=4171)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E57OTk88QuPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DowPzQITQuPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEuqkYObQuPu",
        "colab_type": "code",
        "colab": {},
        "outputId": "1f630287-3751-42d6-e829-55d75c742d23"
      },
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2196, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDY78sP0QuPx",
        "colab_type": "text"
      },
      "source": [
        "PyTorch's defaults work fine for most things however:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a-TpBtcQuPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True)\n",
        "valid_dl = DataLoader(valid_ds, bs, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TJUGNuJQuP0",
        "colab_type": "code",
        "colab": {},
        "outputId": "aaaca3c4-5257-4ba0-dc9c-d5694f07cfe1"
      },
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "\n",
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1029, grad_fn=<NllLossBackward>), tensor(0.9688))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQVSsW8xQuP3",
        "colab_type": "text"
      },
      "source": [
        "Note that PyTorch's `DataLoader`, if you pass `num_workers`, will use multiple threads to call your `Dataset`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm3tyGHVQuP4",
        "colab_type": "text"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKTOuJQFQuP5",
        "colab_type": "text"
      },
      "source": [
        "You **always** should also have a [validation set](http://www.fast.ai/2017/11/13/validation-sets/), in order to identify if you are overfitting.\n",
        "\n",
        "We will calculate and print the validation loss at the end of each epoch.\n",
        "\n",
        "(Note that we always call `model.train()` before training, and `model.eval()` before inference, because these are used by layers such as `nn.BatchNorm2d` and `nn.Dropout` to ensure appropriate behaviour for these different phases.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xZAB7MdQuP5",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=4260)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go4sHR4sQuP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    for epoch in range(epochs):\n",
        "        # Handle batchnorm / dropout\n",
        "        model.train()\n",
        "#         print(model.training)\n",
        "        for xb,yb in train_dl:\n",
        "            loss = loss_func(model(xb), yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "#         print(model.training)\n",
        "        with torch.no_grad():\n",
        "            tot_loss,tot_acc = 0.,0.\n",
        "            for xb,yb in valid_dl:\n",
        "                pred = model(xb)\n",
        "                tot_loss += loss_func(pred, yb)\n",
        "                tot_acc  += accuracy (pred,yb)\n",
        "        nv = len(valid_dl)\n",
        "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
        "    return tot_loss/nv, tot_acc/nv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzDY1dwFQuP8",
        "colab_type": "text"
      },
      "source": [
        "*Question*: Are these validation results correct if batch size varies?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFlY502YQuP9",
        "colab_type": "text"
      },
      "source": [
        "`get_dls` returns dataloaders for the training and validation sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiHMXJagQuP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
        "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
        "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi-A9JiNQuQA",
        "colab_type": "text"
      },
      "source": [
        "Now, our whole process of obtaining the data loaders and fitting the model can be run in 3 lines of code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqmoqJHKQuQB",
        "colab_type": "code",
        "colab": {},
        "outputId": "fe732acb-6aa1-4699-88e2-eb8922b0e558"
      },
      "source": [
        "train_dl,valid_dl = get_dls(train_ds, valid_ds, bs)\n",
        "model,opt = get_model()\n",
        "loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor(0.1573) tensor(0.9533)\n",
            "1 tensor(0.5863) tensor(0.8684)\n",
            "2 tensor(0.1299) tensor(0.9609)\n",
            "3 tensor(0.1178) tensor(0.9664)\n",
            "4 tensor(0.1283) tensor(0.9625)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmEY_OMrQuQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert acc>0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ3uAkynQuQM",
        "colab_type": "text"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTLvotR_QuQN",
        "colab_type": "code",
        "colab": {},
        "outputId": "07908840-785c-470c-e09a-6d3bd5a96b24"
      },
      "source": [
        "!python notebook2script.py 03_minibatch_training.ipynb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 03_minibatch_training.ipynb to nb_03.py\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8ziUBp5QuQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}